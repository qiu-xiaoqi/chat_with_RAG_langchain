{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "embedding_key = os.environ['EMBEDDING_KEY']\n",
    "\n",
    "openai.api_key  = embedding_key\n",
    "# embedding = SentenceTransformerEmbeddings(model_name=\"moka-ai/m3e-base\")\n",
    "embedding = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    api_key=embedding_key,\n",
    "    base_url=\"https://api.zhizengzeng.com/v1/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\柒\\AppData\\Local\\Temp\\ipykernel_29836\\525054440.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数量：1280\n"
     ]
    }
   ],
   "source": [
    "persist_directory = '../vector_db/chroma'\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")\n",
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的内容数：10\n"
     ]
    }
   ],
   "source": [
    "question=\"llm_universe\"\n",
    "sim_docs = vectordb.similarity_search(question,k=10)\n",
    "print(f\"检索到的内容数：{len(sim_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的第0个内容: \n",
      "llm-universe Summary\n",
      "\n",
      "这个仓库名是 llm-universe，这仓库内容主要是提供一个面向初学者的教程，旨在通过阿里云服务器和个人知识库助手项目，教授大模型应用开发的基础知识和技能。教程内容包括大模型简介、API调用、知识库搭建、RAG应用构建及验证迭代等，分为入门、进阶技巧和应用实例三部分，适合具备基础Python能力的开发者学习。\n",
      "--------------\n",
      "检索到的第1个内容: \n",
      "hands-on-llm Summary\n",
      "\n",
      "这个仓库名是hands-on-llm，这仓库内容主要是关于大型语言模型（LLM）的实践操作和学习的资源集合。\n",
      "--------------\n",
      "检索到的第2个内容: \n",
      "llm-research Summary\n",
      "\n",
      "这个仓库名是llm-research，这仓库内容主要是致力于建立一个大型语言模型（LLM）领域的论文解读笔记仓库，集结LLM领域的经典论文并提供解读笔记，包括简版和精读版，旨在帮助研究人员快速了解LLM领域的重要论文和核心思想。项目规划包括内容整理、笔记撰写和质量审核，计划在三四个月内完成。\n",
      "--------------\n",
      "检索到的第3个内容: \n",
      "llms-from-scratch-cn Summary\n",
      "\n",
      "这个仓库名是 llms-from-scratch-cn，这仓库内容主要是提供一个从零开始构建大型语言模型（LLM）的实践教程，涵盖了从基础理论到实际编码的系统化学习路径。项目包括详细的代码示例和深度学习资源，帮助开发者和研究者掌握创建大语言模型的核心技术，特别是GLM4、Llama3、RWKV6等模型的架构实现。项目强调实践导向，通过清晰的教程和简洁的代码，使学习者能够深入理解大模型的原理并进行实际操作。\n",
      "--------------\n",
      "检索到的第4个内容: \n",
      "self-llm Summary\n",
      "\n",
      "这个仓库名是self-llm，这仓库内容主要是围绕开源大模型的使用和部署，提供详细的教程和指南，包括环境配置、模型部署、微调方法等，旨在帮助初学者和研究者更好地理解和应用开源大模型。项目还涵盖了多个主流开源模型的部署和微调教程，并鼓励社区成员参与贡献。\n",
      "--------------\n",
      "检索到的第5个内容: \n",
      "llm-deploy Summary\n",
      "\n",
      "这个仓库名是llm-deploy，这仓库内容主要是关于大型语言模型（LLM）推理和部署的理论与实践教程。它旨在为算法工程师和对推理部署感兴趣的同学提供入门资料，涵盖模型和服务优化实战，并由多位有实践经验的工程师共同贡献。项目亮点包括推理部署相关理论与实践，以及模型和服务优化的实战经验。此外，仓库还提供了参与贡献的指南和贡献者名单。\n",
      "--------------\n",
      "检索到的第6个内容: \n",
      "llm-cookbook Summary\n",
      "\n",
      "这个仓库名是 llm-cookbook，这仓库内容主要是面向开发者的大模型手册，旨在帮助国内开发者入门和实践大模型（LLM）相关技术。项目基于吴恩达的大模型课程，翻译并复现了11门课程，涵盖从Prompt Engineering到RAG开发、模型微调的全流程。项目提供在线阅读和PDF版本，支持中文学习者学习LLM开发，并鼓励开发者贡献课程复现。项目亮点包括中文Prompt设计和国内流畅访问的中文教程。\n",
      "--------------\n",
      "检索到的第7个内容: \n",
      "在本模块，我们将与读者分享提升大语言模型应用效果的各种技巧和最佳实践。书中内容涵盖广泛，包括软件开发提示词设计、文本总结、推理、转换、扩展以及构建聊天机器人等语言模型典型应用场景。我们衷心希望该课程能激发读者的想象力，开发出更出色的语言模型应用。\n",
      "\n",
      "随着 LLM 的发展，其大致可以分为两种类型，后续称为基础 LLM 和指令微调（Instruction Tuned）LLM。基础LLM是基于文本训练数据，训练出预测下一个单词能力的模型。其通常通过在互联网和其他来源的大量数据上训练，来确定紧接着出现的最可能的词。例如，如果你以“从前，有一只独角兽”作为 Prompt ，基础 LLM 可能会继续预测“她与独角兽朋友共同生活在一片神奇森林中”。但是，如果你以“法国的首都是什么”为 Prompt ，则基础 LLM 可能会根据互联网上的文章，将回答预测为“法国最大的城市是什么？法国的人口是多少？”，因为互联网上的文章很可能是有关法国国家的问答题目列表。\n",
      "--------------\n",
      "检索到的第8个内容: \n",
      "因此，本课程将重点介绍针对指令微调 LLM 的最佳实践，我们也建议您将其用于大多数使用场景。当您使用指令微调 LLM 时，您可以类比为向另一个人提供指令（假设他很聪明但不知道您任务的具体细节）。因此，当 LLM 无法正常工作时，有时是因为指令不够清晰。例如，如果您想问“请为我写一些关于阿兰·图灵( Alan Turing )的东西”，在此基础上清楚表明您希望文本专注于他的科学工作、个人生活、历史角色或其他方面可能会更有帮助。另外您还可以指定回答的语调， 来更加满足您的需求，可选项包括专业记者写作，或者向朋友写的随笔等。\n",
      "\n",
      "如果你将 LLM 视为一名新毕业的大学生，要求他完成这个任务，你甚至可以提前指定他们应该阅读哪些文本片段来写关于阿兰·图灵的文本，这样能够帮助这位新毕业的大学生更好地完成这项任务。本书的下一章将详细阐释提示词设计的两个关键原则：清晰明确和给予充足思考时间。\n",
      "--------------\n",
      "检索到的第9个内容: \n",
      "so-large-lm Summary\n",
      "\n",
      "这个仓库名是so-large-lm，这仓库内容主要是提供一个全面的大规模预训练语言模型教程，涵盖从数据准备、模型构建到训练、评估及法律道德等方面的知识。项目旨在为研究者和从业者提供深入的理论和实践指导，推动大模型技术的发展和应用。\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i, sim_doc in enumerate(sim_docs):\n",
    "    print(f\"检索到的第{i}个内容: \\n{sim_doc.page_content}\", end=\"\\n--------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
